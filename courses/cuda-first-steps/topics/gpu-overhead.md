# トピック: なぜ小さいデータではGPUが遅いのか

## メタ情報

- **ID**: gpu-overhead
- **難易度**: 初級
- **所要時間**: 3-5分（対話形式）/ 1-2分（読み物）
- **カテゴリ**: パフォーマンス

## 前提知識

- Stage 3完了

## このトピックで学べること

- GPUのオーバーヘッドの概念
- データサイズとGPU効率の関係
- GPUが有効なケースの見極め方

## 関連ステージ

- Stage 3: 速度を測ってみる

## 要点（ドキュメント形式用）

GPUには固定の**オーバーヘッド**があります。

### オーバーヘッドの内訳

1. **メモリ確保・解放**: `cudaMalloc`, `cudaFree`
2. **データ転送**: `cudaMemcpy` でCPU⇔GPU間を転送
3. **カーネル起動**: GPUを起動するコスト

これらの時間は、データサイズに関わらずほぼ一定です。

### 計算式

```
GPU時間 = オーバーヘッド + 計算時間
```

- 小さいデータ: オーバーヘッド >> 計算時間 → CPU勝ち
- 大きいデータ: オーバーヘッド << 計算時間 → GPU勝ち

### 具体例

| データサイズ | CPU時間 | GPU時間 | 勝者 |
|-------------|---------|---------|------|
| 1,000 | 0.00001秒 | 0.001秒 | CPU |
| 1,000,000 | 0.01秒 | 0.002秒 | GPU |

## 対話形式の教え方ガイド（先生用）

### 導入

「データが少ないとCPUの方が速いのはなぜ？」

### 説明の流れ

1. **オーバーヘッドの存在を説明**
2. **計算式で理解**
   - GPU時間 = オーバーヘッド + 計算時間
3. **データサイズによる逆転を示す**

## クリア条件（オプション）

- [ ] オーバーヘッドの概念を説明できる
- [ ] GPUが有利になるデータサイズを理解している

## 補足情報

### 参考リンク

- [CUDA C++ Best Practices Guide - Performance Metrics](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/)
