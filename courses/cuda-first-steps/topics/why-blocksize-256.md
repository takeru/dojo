# トピック: なぜblockSize=256なの？

## メタ情報

- **ID**: why-blocksize-256
- **難易度**: 初級
- **所要時間**: 3-5分（対話形式）/ 1-2分（読み物）
- **カテゴリ**: パフォーマンス

## 前提知識

- Stage 4完了

## このトピックで学べること

- Warpとブロックサイズの関係
- 256が人気の理由
- ブロックサイズ選択の指針

## 関連ステージ

- Stage 4: ベクトル加算で基礎固め

## 要点（ドキュメント形式用）

GPUのアーキテクチャでは、スレッドは**Warp**という32スレッド単位で実行されます。

### 推奨ブロックサイズ

ブロックサイズは**32の倍数**にするのが推奨：
- 32, 64, 128, 256, 512, 1024

### 256が人気の理由

- **適度なサイズ**: 大きすぎず小さすぎず
- **互換性**: ほとんどのGPUで問題なく動く
- **オキュパンシー**: GPU利用率が良い
- **8 Warp**: 32 × 8 = 256で管理しやすい

### ブロックサイズの制限

- 最大: 1024スレッド/ブロック
- 2次元/3次元の場合は積が1024以下

## 対話形式の教え方ガイド（先生用）

### 導入

「ブロックサイズはなぜ256がよく使われるの？」

### 説明の流れ

1. **Warpの説明**
   - 32スレッド単位で実行
   - 32の倍数が効率的

2. **256の利点**
   - 8 Warp = 256スレッド
   - 多くのケースで良い性能

3. **実際には試すことが大事**
   「最適な値はケースバイケース」

## クリア条件（オプション）

- [ ] Warpとブロックサイズの関係を理解している
- [ ] 256が使われる理由を説明できる

## 補足情報

### 参考リンク

- [CUDA C++ Programming Guide - SIMT Architecture](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture)
